{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "64ce7843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 工具\n",
    "# 深度学习：keras\n",
    "# 传统机器学习：sklearn\n",
    "# 参与比较的机器学习方法\n",
    "\n",
    "# CNN \n",
    "# LSTM \n",
    "# 朴素贝叶斯\n",
    "# KNN\n",
    "# SVM\n",
    "# Logisticre Gression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cd71f0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow==2.2\n",
    "# !pip install numpy\n",
    "# !pip install gensim\n",
    "\n",
    "# print(np.__version__)\n",
    "# print(tensorflow.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "be7fc9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_text(train_texts,train_labels,test_texts,test_labels):\n",
    "    #coding:utf-8\n",
    "    print ('*load texts:')\n",
    "    train_texts = open(train_texts,encoding='UTF-8').read().split('\\n')\n",
    "    train_labels = open(train_labels,encoding='UTF-8').read().split('\\n')\n",
    "    test_texts = open(test_texts,encoding='UTF-8').read().split('\\n')\n",
    "    test_labels = open(test_labels,encoding='UTF-8').read().split('\\n')\n",
    "    all_texts = train_texts + test_texts\n",
    "    all_labels = train_labels + test_labels\n",
    "    return all_texts,all_labels,train_texts,train_labels,test_texts,test_labels\n",
    "    \n",
    "def creat_tokenizer(all_texts):\n",
    "    print ('*tokenizer:')\n",
    "    from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "    from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "    from tensorflow.keras.utils import to_categorical\n",
    "    import numpy as np\n",
    "\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(all_texts)\n",
    "    sequences = tokenizer.texts_to_sequences(all_texts)\n",
    "    word_index = tokenizer.word_index\n",
    "    print('Found %s unique tokens.' % len(word_index))\n",
    "    data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "    labels = to_categorical(np.asarray(all_labels))\n",
    "    print('Shape of data tensor:', data.shape)\n",
    "    print('Shape of label tensor:', labels.shape)\n",
    "    return data,labels,word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2be6e75e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*load texts:\n",
      "*tokenizer:\n",
      "Found 150140 unique tokens.\n",
      "Shape of data tensor: (11180, 100)\n",
      "Shape of label tensor: (11180, 14)\n",
      "*split data set:\n",
      "train docs: 7155\n",
      "val docs: 1789\n",
      "test docs: 2236\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 100\n",
    "EMBEDDING_DIM = 200\n",
    "VALIDATION_SPLIT = 0.16\n",
    "TEST_SPLIT = 0.2\n",
    "\n",
    "all_texts,all_labels,train_texts,train_labels,test_texts,test_labels=load_text('text.txt','categroy.txt','text.txt','categroy.txt')\n",
    "\n",
    "data,labels,word_index=creat_tokenizer(all_texts)\n",
    "\n",
    "print ('*split data set:')\n",
    "# split the data into training set, validation set, and test set\n",
    "p1 = int(len(data)*(1-VALIDATION_SPLIT-TEST_SPLIT))\n",
    "p2 = int(len(data)*(1-TEST_SPLIT))\n",
    "x_train = data[:p1]\n",
    "y_train = labels[:p1]\n",
    "x_val = data[p1:p2]\n",
    "y_val = labels[p1:p2]\n",
    "x_test = data[p2:]\n",
    "y_test = labels[p2:]\n",
    "print ('train docs: '+str(len(x_train)))\n",
    "print ('val docs: '+str(len(x_val)))\n",
    "print ('test docs: '+str(len(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e34b4978",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_define(embedding_dim,max_sequence_length):\n",
    "    #define for CNN\n",
    "    print ('*define model CNN:')\n",
    "    from tensorflow.keras.layers import Dense, Input, Flatten, Dropout\n",
    "    from tensorflow.keras.layers import Conv1D, MaxPooling1D, Embedding, GlobalMaxPooling1D\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.utils import plot_model\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(len(word_index) + 1, embedding_dim, input_length=max_sequence_length))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv1D(250, 3, padding='valid', activation='relu', strides=1))\n",
    "    model.add(MaxPooling1D(3))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(embedding_dim, activation='relu'))\n",
    "    model.add(Dense(labels.shape[1], activation='softmax'))\n",
    "    model.summary()\n",
    "    # plot_model(model, to_file='model.png',show_shapes=True)\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='rmsprop',metrics=['acc'])\n",
    "    print (model.metrics_names)\n",
    "    return model\n",
    "\n",
    "def LSTM_define(embedding_dim,max_sequence_length):\n",
    "    #trainning for lstm\n",
    "    print ('*define model lstm：')\n",
    "    from tensorflow.keras.layers import Dense, Input, Flatten, Dropout\n",
    "    from tensorflow.keras.layers import LSTM, Embedding\n",
    "    from tensorflow.keras.models import Sequential\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(len(word_index) + 1, embedding_dim, input_length=max_sequence_length))\n",
    "    model.add(LSTM(200, dropout=0.2, recurrent_dropout=0.2))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(labels.shape[1], activation='softmax'))\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='rmsprop',metrics=['acc'])\n",
    "    print (model.metrics_names)\n",
    "    return model\n",
    "    \n",
    "def model_train(model_name,model):\n",
    "    model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=2, batch_size=128)\n",
    "    model.save(model_name)\n",
    "\n",
    "    print ('*testing model:')\n",
    "    print (model.evaluate(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "5e0fe03e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*define model CNN:\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_16 (Embedding)     (None, 100, 200)          30028200  \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 100, 200)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 98, 250)           150250    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 32, 250)           0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 8000)              0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 200)               1600200   \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 14)                2814      \n",
      "=================================================================\n",
      "Total params: 31,781,464\n",
      "Trainable params: 31,781,464\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "[]\n",
      "Epoch 1/2\n",
      "56/56 [==============================] - 9s 154ms/step - loss: 2.3286 - acc: 0.2186 - val_loss: 1.7851 - val_acc: 0.2745\n",
      "Epoch 2/2\n",
      "56/56 [==============================] - 9s 154ms/step - loss: 1.3595 - acc: 0.5546 - val_loss: 0.7218 - val_acc: 0.7982\n",
      "*testing model:\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 1.2970 - acc: 0.5957\n",
      "[1.2970026731491089, 0.5957066416740417]\n"
     ]
    }
   ],
   "source": [
    "model=CNN_define(EMBEDDING_DIM,MAX_SEQUENCE_LENGTH)\n",
    "model_train('CNN.h5',model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f15f7fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*define model lstm：\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_17 (Embedding)     (None, 100, 200)          30028200  \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 14)                2814      \n",
      "=================================================================\n",
      "Total params: 30,351,814\n",
      "Trainable params: 30,351,814\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "[]\n",
      "Epoch 1/2\n",
      "56/56 [==============================] - 42s 749ms/step - loss: 2.4615 - acc: 0.1814 - val_loss: 2.4138 - val_acc: 0.1308\n",
      "Epoch 2/2\n",
      "56/56 [==============================] - 42s 757ms/step - loss: 1.9138 - acc: 0.3783 - val_loss: 1.9268 - val_acc: 0.4561\n",
      "*testing model:\n",
      "70/70 [==============================] - 3s 37ms/step - loss: 1.7252 - acc: 0.4365\n",
      "[1.725166916847229, 0.43649372458457947]\n"
     ]
    }
   ],
   "source": [
    "model=LSTM_define(EMBEDDING_DIM,MAX_SEQUENCE_LENGTH)\n",
    "model_train('LSTM.h5',model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b53e0b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfid(all_texts):\n",
    "    print ('*doc to var:')\n",
    "    from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer   \n",
    "    count_v0= CountVectorizer();  \n",
    "    counts_all = count_v0.fit_transform(all_texts);\n",
    "    count_v1= CountVectorizer(vocabulary=count_v0.vocabulary_);  \n",
    "    counts_train = count_v1.fit_transform(train_texts);   \n",
    "    print (\"the shape of train is \"+repr(counts_train.shape))  \n",
    "    count_v2 = CountVectorizer(vocabulary=count_v0.vocabulary_);  \n",
    "    counts_test = count_v2.fit_transform(test_texts);  \n",
    "    print (\"the shape of test is \"+repr(counts_test.shape))\n",
    "\n",
    "    tfidftransformer = TfidfTransformer();    \n",
    "    train_data = tfidftransformer.fit(counts_train).transform(counts_train);\n",
    "    test_data = tfidftransformer.fit(counts_test).transform(counts_test); \n",
    "\n",
    "    x_train = train_data\n",
    "    y_train = train_labels\n",
    "    x_test = test_data\n",
    "    y_test = test_labels\n",
    "    return x_train,y_train,x_test,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d6849f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*doc to var:\n",
      "the shape of train is (5590, 145672)\n",
      "the shape of test is (5590, 145672)\n"
     ]
    }
   ],
   "source": [
    "x_train,y_train,x_test,y_test=tfid(all_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "1e59a858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*KNN:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:211: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K= 1, precision_score:1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:211: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K= 2, precision_score:0.8395348837209302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:211: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K= 3, precision_score:0.8518783542039357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:211: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K= 4, precision_score:0.8339892665474061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:211: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K= 5, precision_score:0.8311270125223613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:211: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K= 6, precision_score:0.8196779964221824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:211: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K= 7, precision_score:0.8223613595706619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:211: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K= 8, precision_score:0.8178890876565296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:211: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K= 9, precision_score:0.8194991055456172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:211: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K= 10, precision_score:0.8161001788908766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:211: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K= 11, precision_score:0.8141323792486583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:211: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K= 12, precision_score:0.8110912343470483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:211: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K= 13, precision_score:0.8114490161001789\n",
      "K= 14, precision_score:0.807871198568873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:211: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "print ('*KNN:')\n",
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "\n",
    "for x in range(1,15):  \n",
    "    knnclf = KNeighborsClassifier(n_neighbors=x)\n",
    "    knnclf.fit(x_train,y_train)  \n",
    "    preds = knnclf.predict(x_test);\n",
    "    num = 0\n",
    "    preds = preds.tolist()\n",
    "    for i,pred in enumerate(preds):\n",
    "        if int(pred) == int(y_test[i]):\n",
    "            num += 1\n",
    "    print ('K= '+str(x)+', precision_score:' + str(float(num) / len(preds)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "9bba25e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*SVM：\n",
      "precision_score:0.9837209302325581\n"
     ]
    }
   ],
   "source": [
    "print ('*SVM：')\n",
    "from sklearn.svm import SVC   \n",
    "svclf = SVC(kernel = 'linear') \n",
    "svclf.fit(x_train,y_train)  \n",
    "preds = svclf.predict(x_test);  \n",
    "num = 0\n",
    "preds = preds.tolist()\n",
    "for i,pred in enumerate(preds):\n",
    "    if int(pred) == int(y_test[i]):\n",
    "        num += 1\n",
    "print ('precision_score:' + str(float(num) / len(preds)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d75c41e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*Naive Bayes：\n",
      "precision_score:0.9824686940966011\n"
     ]
    }
   ],
   "source": [
    "print ('*Naive Bayes：')\n",
    "from sklearn.naive_bayes import MultinomialNB  \n",
    "from sklearn import metrics\n",
    "clf = MultinomialNB(alpha = 0.01)   \n",
    "clf.fit(x_train, y_train);  \n",
    "preds = clf.predict(x_test);\n",
    "num = 0\n",
    "preds = preds.tolist()\n",
    "for i,pred in enumerate(preds):\n",
    "    if int(pred) == int(y_test[i]):\n",
    "        num += 1\n",
    "print ('precision_score:' + str(float(num) / len(preds)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8cf3cb4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*Logisticre Gression：\n",
      "precision_score:1.0\n"
     ]
    }
   ],
   "source": [
    "print ('*Logisticre Gression：')\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "log =  LogisticRegression(C=1e10,max_iter=10000) \n",
    "log.fit(x_train, y_train);  \n",
    "preds = log.predict(x_test);\n",
    "num = 0\n",
    "preds = preds.tolist()\n",
    "for i,pred in enumerate(preds):\n",
    "    if int(pred) == int(y_test[i]):\n",
    "        num += 1\n",
    "print ('precision_score:' + str(float(num) / len(preds)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd4e5b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
